{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The transformers ```pipeline()``` function simplifies classic NLP tasks such as text classification, named entity recognition, question answering, summarization, translation, and, and we will see here, text generation into just a few lines of code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model='gpt2')\n",
    "generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now save the three classic questions from the cognitive reflection test as a list of strings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?',\n",
    "    'If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?',\n",
    "    'In a lake, there is a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the patch to cover the entire lake, how long would it take for the patch to cover half of the lake?'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now use the generator to produce a response based on each prompt. This takes:\n",
    "1. ```prompts```\n",
    "2. ```max_length```: Sets an upper bound on the length of the generated text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generating outputs\n",
    "outputs = generator(prompts, max_length=100)\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Printing\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print('-----------------------------')\n",
    "    print('\\033[1m' + prompt + '\\033[0m')\n",
    "    print('-----------------------------')\n",
    "\n",
    "    # Getting the generated text output from the output dictionary\n",
    "    output = output[0]['generated_text']\n",
    "\n",
    "    # Dropping the prompt from the output for nicer formatting\n",
    "    print(output.replace(prompt, '').strip())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ideas for Exercise:\n",
    "1. Based on your understanding of transformers, why do you think a model such as GPT performs so badly on this test?\n",
    "2. Try editing the prompt to give GPT-2 clues. Does it help?\n",
    "3. Have a look on https://huggingface.co/models?pipeline_tag=text-generation&sort=trending to see if you can find a model more suitable for solving maths problems."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
