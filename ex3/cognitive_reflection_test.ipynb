{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Installing packages in Google Colab environment\n",
    "    !pip install transformers\n",
    "\n",
    "    # Mounting google drive to enable access to data files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Changing working directory to ex1\n",
    "    %cd /content/drive/MyDrive/LLM4JDM/ex3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T11:28:46.328676Z",
     "start_time": "2023-08-19T11:28:46.326054Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The transformers ```pipeline()``` function simplifies classic NLP tasks such as text classification, named entity recognition, question answering, summarization, translation, and, and we will see here, text generation into just a few lines of code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T11:28:51.899968Z",
     "start_time": "2023-08-19T11:28:49.952634Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1aefb3314cf243dcbf4cee458d2b550a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x7fdc9a1f1250>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model='gpt2')\n",
    "generator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T11:29:21.246794Z",
     "start_time": "2023-08-19T11:28:51.901381Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now save the three classic questions from the cognitive reflection test as a list of strings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?',\n",
    "    'If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?',\n",
    "    'In a lake, there is a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the patch to cover the entire lake, how long would it take for the patch to cover half of the lake?'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T11:31:36.894573Z",
     "start_time": "2023-08-19T11:31:36.889681Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now use the generator to produce a response based on each prompt. This takes:\n",
    "1. ```prompts```: the list of prompts we defined above.\n",
    "2. ```max_length```: Sets an upper bound on the length of the generated text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "\u001B[1mA bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\u001B[0m\n",
      "-----------------------------\n",
      "Baseball-Reference's \"baseball player\" cost estimates were taken from a database of available baseball books and the baseball for sale at stores across America. They're also the ballpark's baseball tables. Baseball-Reference calculated a baseball player's \"baseball buyback\" to go up based on his buyback value, assuming that\n",
      "-----------------------------\n",
      "\u001B[1mIf it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\u001B[0m\n",
      "-----------------------------\n",
      "The second, more important question is how far would any app take such a huge effort. Some of your most successful apps use over 100 different types of widgets. So that the cost varies for each user is probably much in the 200+ apps that I already mentioned.\n",
      "\n",
      "\n",
      "The third question is how much time would it take to make a huge app? I would be\n",
      "-----------------------------\n",
      "\u001B[1mIn a lake, there is a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the patch to cover the entire lake, how long would it take for the patch to cover half of the lake?\u001B[0m\n",
      "-----------------------------\n",
      "I guess that's what they all say. For every day that I've been here, I've done 2.5 inches of water incrementally over there with no change in the rainfall. And then, I'm sitting here, in the desert\n"
     ]
    }
   ],
   "source": [
    "# Generating outputs\n",
    "outputs = generator(prompts, max_length=100)\n",
    "\n",
    "# Printing\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print('-----------------------------')\n",
    "    print('\\033[1m' + prompt + '\\033[0m')\n",
    "    print('-----------------------------')\n",
    "\n",
    "    # Getting the generated text output from the output dictionary\n",
    "    output = output[0]['generated_text']\n",
    "\n",
    "    # Dropping the prompt from the output for nicer formatting\n",
    "    print(output.replace(prompt, '').strip())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T11:33:51.235018Z",
     "start_time": "2023-08-19T11:33:45.805038Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Exercises*:\n",
    "1. Based on your understanding of transformers, why do you think a model such as GPT performs so badly on this test?\n",
    "2. Try editing the prompt to give GPT-2 clues. Does it help?\n",
    "3. Try and implement an API call to gpt3.5 or gpt4 on your own.\n",
    "4. Try to set up repeated calls to the API (e.g. using a loop). This would be useful for feeding multiple text samples into the model."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
